{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Part 3 - Modeling & Evaluation\n",
    "\n",
    "_Author: Sharnique Beck (BOS)_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer and Model imports:\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pre-processed data\n",
    "data = pd.read_csv('../data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doom patrol trailer released</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justice league fight future 6th dimension</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>themiscyra atlantis join un</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aquaman movie spoiler brief history aquaman oc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anyone else hate comic change match look esthe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  y\n",
       "0                       doom patrol trailer released  0\n",
       "1          justice league fight future 6th dimension  0\n",
       "2                        themiscyra atlantis join un  0\n",
       "3  aquaman movie spoiler brief history aquaman oc...  0\n",
       "4  anyone else hate comic change match look esthe...  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['title']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.501003\n",
       "1    0.498997\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
    "                                                 random_state=42,\n",
    "                                                 stratify=y) # account for slight class unbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tvect = TfidfVectorizer()\n",
    "lr = LogisticRegression()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates 2 Logistic Regression pipelines using count and tfidf vectorizers\n",
    "cv_lr_pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('lr', lr)\n",
    "])\n",
    "tfidf_lr_pipe = Pipeline([\n",
    "    ('tvect', tvect),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "# Creates two Naive Bayes pipelines with Multinomial and binomial NB\n",
    "m_nv_pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('mnb', mnb)\n",
    "])\n",
    "b_nv_pipe = Pipeline([\n",
    "    ('tvect', tvect),\n",
    "    ('bnb', bnb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search params\n",
    "params_1 = {\n",
    "    'cv__max_features':[None,5000,10000],\n",
    "    'cv__ngram_range':[(1,1),(1,2)]\n",
    "}\n",
    "params_2 = {\n",
    "    'tvect__max_features':[None,4000,5000,10000],\n",
    "    'tvect__ngram_range':[(1,1),(1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a grid search given a pipeline, set of params to search over and data to train on,\n",
    "# prints out best params found, and train w/test score\n",
    "def gs(pipe,params,X_tr,y_tr,X,y):\n",
    "    \n",
    "    gs = GridSearchCV(pipe,param_grid=params)\n",
    "    \n",
    "    gs.fit(X_tr,y_tr);\n",
    "    \n",
    "    print('Best parameters:', gs.best_params_)\n",
    "    print('Best Score:', gs.best_score_)\n",
    "    print('Test Score:', gs.score(X,y))\n",
    "    \n",
    "    return gs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'cv__max_features': None, 'cv__ngram_range': (1, 2)}\n",
      "Best Score: 0.8927664126220083\n",
      "Test Score: 0.892498997192138\n"
     ]
    }
   ],
   "source": [
    "# count vector\n",
    "gs(cv_lr_pipe,params_1,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tvect__max_features': 5000, 'tvect__ngram_range': (1, 2)}\n",
      "Best Score: 0.8887551811739537\n",
      "Test Score: 0.8953068592057761\n"
     ]
    }
   ],
   "source": [
    "# tfidf vector\n",
    "gs(tfidf_lr_pipe,params_2,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'cv__max_features': None, 'cv__ngram_range': (1, 2)}\n",
      "Best Score: 0.8937023666265543\n",
      "Test Score: 0.8977135980746089\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "gs(m_nv_pipe,params_1,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tvect__max_features': None, 'tvect__ngram_range': (1, 2)}\n",
      "Best Score: 0.8967776440700629\n",
      "Test Score: 0.9037304452466908\n"
     ]
    }
   ],
   "source": [
    "# Binomial NB\n",
    "best = gs(b_nv_pipe,params_2,X_train,y_train,X_test,y_test)\n",
    "# best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest  vs. Extra Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect= CountVectorizer(ngram_range=(1,2))\n",
    "X_train_cv = cvect.fit_transform(X_train)\n",
    "X_test_cv = cvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612113918973124"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf,X_train_cv,y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869634977938227"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(et,X_train_cv,y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8814012568525204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_split': 4, 'n_estimators': 30}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because Extra Trees scored slightly better than random forest cross val score I\n",
    "# used its model to grid search\n",
    "et = ExtraTreesClassifier()\n",
    "et_params = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,4],\n",
    "#     'max_features': ['auto',1.0]      took too long to run\n",
    "}\n",
    "et_gs = GridSearchCV(et, param_grid=et_params)\n",
    "et_gs.fit(X_train_cv, y_train)\n",
    "print(et_gs.best_score_)\n",
    "et_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9949191068324642\n",
      "test score: 0.8728439630966707\n"
     ]
    }
   ],
   "source": [
    "print('train score:',et_gs.score(X_train_cv, y_train))\n",
    "\n",
    "print('test score:',et_gs.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best scoring model to evaluate\n",
    "predictions = best.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted neg</th>\n",
       "      <th>predicted pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>1096</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>87</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted neg  predicted pos\n",
       "actual neg           1096            153\n",
       "actual pos             87           1157"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert confusion matrix to dataframe\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                    columns = ['predicted neg', 'predicted pos'],\n",
    "                    index = ['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.37304452466908"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model accuracy\n",
    "accuracy =(1096+1157)/(1096+153+87+1157)\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
